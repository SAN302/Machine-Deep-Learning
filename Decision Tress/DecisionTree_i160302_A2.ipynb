{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict  # default dictionary \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "count   149.000000  149.000000   149.000000  149.000000\n",
      "mean      5.848322    3.051007     3.774497    1.205369\n",
      "std       0.828594    0.433499     1.759651    0.761292\n",
      "min       4.300000    2.000000     1.000000    0.100000\n",
      "25%       5.100000    2.800000     1.600000    0.300000\n",
      "50%       5.800000    3.000000     4.400000    1.300000\n",
      "75%       6.400000    3.300000     5.100000    1.800000\n",
      "max       7.900000    4.400000     6.900000    2.500000\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('./iris.data')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Set Dimensions= (149, 4)  True Class labels dimensions (149,)\n",
      "(149, 4)\n",
      "(149,)\n"
     ]
    }
   ],
   "source": [
    "# Get your data in matrix\n",
    "X=np.asarray(data[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y=np.asarray(data['Class'].dropna())\n",
    "print (\" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape)  \n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here data is being set so that there are only two classes\n",
    "Y[Y=='Iris-virginica']='Iris-versicolor'\n",
    "Y[Y=='Iris-versicolor']=1\n",
    "Y[Y=='Iris-setosa']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y.reshape((-1, 1))\n",
    "X=np.append(X,Y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.2 3.4 5.4 2.3 1]\n",
      " [6.4 2.8 5.6 2.1 1]\n",
      " [5.0 2.3 3.3 1.0 1]\n",
      " [6.3 2.7 4.9 1.8 1]\n",
      " [6.6 3.0 4.4 1.4 1]\n",
      " [6.2 2.9 4.3 1.3 1]\n",
      " [6.3 2.5 4.9 1.5 1]\n",
      " [7.3 2.9 6.3 1.8 1]\n",
      " [4.4 3.0 1.3 0.2 0]\n",
      " [6.1 2.8 4.0 1.3 1]\n",
      " [4.4 3.2 1.3 0.2 0]\n",
      " [6.1 2.6 5.6 1.4 1]\n",
      " [7.7 2.6 6.9 2.3 1]\n",
      " [5.0 3.6 1.4 0.2 0]\n",
      " [6.0 2.9 4.5 1.5 1]\n",
      " [5.7 3.0 4.2 1.2 1]\n",
      " [5.8 2.7 3.9 1.2 1]\n",
      " [6.5 3.0 5.5 1.8 1]\n",
      " [4.9 3.1 1.5 0.1 0]\n",
      " [5.0 3.5 1.6 0.6 0]\n",
      " [5.7 2.6 3.5 1.0 1]\n",
      " [7.2 3.0 5.8 1.6 1]\n",
      " [6.9 3.2 5.7 2.3 1]\n",
      " [4.9 3.1 1.5 0.1 0]\n",
      " [6.5 3.0 5.2 2.0 1]\n",
      " [6.4 3.2 4.5 1.5 1]\n",
      " [5.3 3.7 1.5 0.2 0]\n",
      " [6.1 3.0 4.9 1.8 1]\n",
      " [4.8 3.0 1.4 0.1 0]\n",
      " [5.6 2.5 3.9 1.1 1]\n",
      " [6.8 3.0 5.5 2.1 1]\n",
      " [5.6 3.0 4.1 1.3 1]\n",
      " [5.6 2.7 4.2 1.3 1]\n",
      " [5.8 2.6 4.0 1.2 1]\n",
      " [4.8 3.0 1.4 0.3 0]\n",
      " [4.8 3.4 1.9 0.2 0]\n",
      " [6.4 3.1 5.5 1.8 1]\n",
      " [4.5 2.3 1.3 0.3 0]\n",
      " [6.0 3.0 4.8 1.8 1]\n",
      " [5.1 3.4 1.5 0.2 0]\n",
      " [6.7 3.1 5.6 2.4 1]\n",
      " [5.4 3.9 1.3 0.4 0]\n",
      " [5.8 2.8 5.1 2.4 1]\n",
      " [6.0 2.7 5.1 1.6 1]\n",
      " [7.7 3.0 6.1 2.3 1]\n",
      " [5.0 3.2 1.2 0.2 0]\n",
      " [6.0 3.4 4.5 1.6 1]\n",
      " [5.0 3.5 1.3 0.3 0]\n",
      " [6.2 2.8 4.8 1.8 1]\n",
      " [4.6 3.1 1.5 0.2 0]\n",
      " [5.6 2.9 3.6 1.3 1]\n",
      " [5.1 3.8 1.6 0.2 0]\n",
      " [6.7 2.5 5.8 1.8 1]\n",
      " [6.5 3.0 5.8 2.2 1]\n",
      " [5.0 3.4 1.5 0.2 0]\n",
      " [6.3 3.3 4.7 1.6 1]\n",
      " [5.1 3.7 1.5 0.4 0]\n",
      " [5.5 2.5 4.0 1.3 1]\n",
      " [5.4 3.9 1.7 0.4 0]\n",
      " [7.4 2.8 6.1 1.9 1]\n",
      " [6.2 2.2 4.5 1.5 1]\n",
      " [5.7 2.8 4.5 1.3 1]\n",
      " [4.3 3.0 1.1 0.1 0]\n",
      " [6.0 2.2 4.0 1.0 1]\n",
      " [6.4 3.2 5.3 2.3 1]\n",
      " [5.8 4.0 1.2 0.2 0]\n",
      " [6.7 3.3 5.7 2.1 1]\n",
      " [5.5 4.2 1.4 0.2 0]\n",
      " [6.7 3.1 4.4 1.4 1]\n",
      " [4.8 3.1 1.6 0.2 0]\n",
      " [5.0 2.0 3.5 1.0 1]\n",
      " [5.0 3.4 1.6 0.4 0]\n",
      " [7.1 3.0 5.9 2.1 1]\n",
      " [5.5 3.5 1.3 0.2 0]\n",
      " [6.1 2.8 4.7 1.2 1]\n",
      " [5.7 3.8 1.7 0.3 0]\n",
      " [7.2 3.2 6.0 1.8 1]\n",
      " [5.7 2.9 4.2 1.3 1]\n",
      " [4.6 3.6 1.0 0.2 0]\n",
      " [5.9 3.2 4.8 1.8 1]\n",
      " [4.9 3.1 1.5 0.1 0]\n",
      " [6.6 2.9 4.6 1.3 1]\n",
      " [4.9 3.0 1.4 0.2 0]\n",
      " [5.2 2.7 3.9 1.4 1]\n",
      " [6.4 2.8 5.6 2.2 1]\n",
      " [5.7 4.4 1.5 0.4 0]\n",
      " [4.4 2.9 1.4 0.2 0]\n",
      " [5.4 3.7 1.5 0.2 0]\n",
      " [4.9 2.4 3.3 1.0 1]\n",
      " [6.7 3.1 4.7 1.5 1]\n",
      " [5.8 2.7 5.1 1.9 1]\n",
      " [5.4 3.0 4.5 1.5 1]\n",
      " [5.1 3.3 1.7 0.5 0]\n",
      " [6.4 2.7 5.3 1.9 1]\n",
      " [6.9 3.1 5.1 2.3 1]\n",
      " [5.2 4.1 1.5 0.1 0]\n",
      " [7.7 2.8 6.7 2.0 1]\n",
      " [5.5 2.4 3.8 1.1 1]\n",
      " [5.9 3.0 5.1 1.8 1]\n",
      " [6.5 3.2 5.1 2.0 1]\n",
      " [5.7 2.5 5.0 2.0 1]\n",
      " [6.3 2.3 4.4 1.3 1]\n",
      " [6.9 3.1 4.9 1.5 1]\n",
      " [7.2 3.6 6.1 2.5 1]\n",
      " [5.1 2.5 3.0 1.1 1]\n",
      " [4.6 3.4 1.4 0.3 0]\n",
      " [5.5 2.4 3.7 1.0 1]\n",
      " [5.1 3.8 1.9 0.4 0]\n",
      " [6.7 3.0 5.2 2.3 1]\n",
      " [7.6 3.0 6.6 2.1 1]\n",
      " [6.4 2.9 4.3 1.3 1]\n",
      " [5.9 3.0 4.2 1.5 1]\n",
      " [6.3 2.5 5.0 1.9 1]\n",
      " [5.4 3.4 1.7 0.2 0]\n",
      " [7.7 3.8 6.7 2.2 1]\n",
      " [6.1 3.0 4.6 1.4 1]\n",
      " [5.4 3.4 1.5 0.4 0]\n",
      " [5.2 3.5 1.5 0.2 0]\n",
      " [6.7 3.0 5.0 1.7 1]\n",
      " [5.1 3.5 1.4 0.3 0]\n",
      " [4.6 3.2 1.4 0.2 0]\n",
      " [6.1 2.9 4.7 1.4 1]\n",
      " [5.5 2.3 4.0 1.3 1]\n",
      " [5.8 2.7 5.1 1.9 1]\n",
      " [5.6 3.0 4.5 1.5 1]\n",
      " [6.3 3.4 5.6 2.4 1]\n",
      " [5.0 3.0 1.6 0.2 0]\n",
      " [6.5 2.8 4.6 1.5 1]\n",
      " [5.7 2.8 4.1 1.3 1]\n",
      " [7.9 3.8 6.4 2.0 1]\n",
      " [4.7 3.2 1.6 0.2 0]\n",
      " [6.3 3.3 6.0 2.5 1]\n",
      " [6.3 2.9 5.6 1.8 1]\n",
      " [4.7 3.2 1.3 0.2 0]\n",
      " [6.0 2.2 5.0 1.5 1]\n",
      " [7.0 3.2 4.7 1.4 1]\n",
      " [6.9 3.1 5.4 2.1 1]\n",
      " [6.8 2.8 4.8 1.4 1]\n",
      " [5.6 2.8 4.9 2.0 1]\n",
      " [4.8 3.4 1.6 0.2 0]\n",
      " [4.9 2.5 4.5 1.7 1]\n",
      " [6.8 3.2 5.9 2.3 1]\n",
      " [5.5 2.6 4.4 1.2 1]\n",
      " [5.1 3.8 1.5 0.3 0]\n",
      " [5.2 3.4 1.4 0.2 0]\n",
      " [6.3 2.8 5.1 1.5 1]\n",
      " [5.8 2.7 4.1 1.0 1]\n",
      " [6.7 3.3 5.7 2.5 1]\n",
      " [5.0 3.3 1.4 0.2 0]]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InfoGain(Data):\n",
    "    tempdata=np.zeros((Data.shape))\n",
    "    f_index=value_maxinfogain=max_infogain=index_maxinfogain=maxweighted_avg=mtotaldata=uc1=lc1=muchild=mlchild=0\n",
    "    setosa_inparent_prob=(Data[:,4]==0).sum()/Data.shape[0]\n",
    "    versicolor_inparent_prob=(Data[:,4]==1).sum()/Data.shape[0]\n",
    "    if(setosa_inparent_prob==0):\n",
    "        setosa_inparent_prob=1\n",
    "    if(versicolor_inparent_prob==0):\n",
    "        versicolor_inparent_prob=1\n",
    "   # print('Setosa prob in parent: ',setosa_inparent_prob)\n",
    "   # print('Versicolor prob in parent: ',versicolor_inparent_prob)\n",
    "    entropy_ofparent=-(setosa_inparent_prob*math.log(setosa_inparent_prob,2)+versicolor_inparent_prob*math.log(versicolor_inparent_prob,2))\n",
    "   # print('Entropy of parent: ',entropy_ofparent,'\\n')\n",
    "    uchild_countsetosa=uchild_countversicolor=lchild_countsetosa=lchild_countversicolor=max_infogain=0\n",
    "    uchild=np.zeros((1,5))\n",
    "    lchild=np.zeros((1,5))\n",
    "    min_of_Data=Data.min(axis=0)\n",
    "    for feature in range(Data.shape[1]-1):\n",
    "        #max_infogain=index_maxinfogain=value_maxinfogain=maxweighted_avg=mtotaldata=uc1=lc1=0\n",
    "        for i in range(Data.shape[0]):\n",
    "            splitpoint=Data[i,feature]#change 0 for other features\n",
    "            for j in range(Data.shape[0]):\n",
    "                if(Data[j,feature]<splitpoint or Data[j,feature]==min_of_Data[feature]):#change 0 for other features\n",
    "                    lchild=np.vstack([lchild,Data[j,:]])\n",
    "                    if(Data[j,4]==1):\n",
    "                        lchild_countversicolor+=1\n",
    "                    elif(Data[j,4]==0):\n",
    "                        lchild_countsetosa+=1\n",
    "                elif(Data[j,feature]>=splitpoint):#change 0 for other features\n",
    "                    uchild=np.vstack([uchild,Data[j,:]])\n",
    "                    if(Data[j,4]==1):\n",
    "                        uchild_countversicolor+=1\n",
    "                    elif(Data[j,4]==0):\n",
    "                        uchild_countsetosa+=1\n",
    "            #print('uchild_countversicolor: ',uchild_countversicolor)\n",
    "            #print('uchild_countsetosa: ',uchild_countsetosa)\n",
    "            #print('lchild_countversicolor: ',lchild_countversicolor)\n",
    "            #print('lchild_countsetosa: ',lchild_countsetosa)\n",
    "            #print('Total: ',uchild_countsetosa+uchild_countversicolor+lchild_countversicolor+lchild_countsetosa)\n",
    "            uchild=np.delete(uchild,(0),axis=0)\n",
    "            #print('uchild shape:',uchild.shape)\n",
    "            #print('uchild:\\n',uchild)\n",
    "            lchild=np.delete(lchild,(0),axis=0)\n",
    "            #print('lchild shape:',lchild.shape)\n",
    "            #print('lchild:\\n',lchild)\n",
    "            uchild_setosaprob=uchild_countsetosa/(uchild_countsetosa+uchild_countversicolor)\n",
    "            uchild_versicolorprob=uchild_countversicolor/(uchild_countsetosa+uchild_countversicolor)\n",
    "            lchild_setosaprob=lchild_countsetosa/(lchild_countversicolor+lchild_countsetosa)\n",
    "            lchild_versicolorprob=lchild_countversicolor/(lchild_countversicolor+lchild_countsetosa)\n",
    "            if(uchild_setosaprob==0):\n",
    "                uchild_setosaprob=1\n",
    "            if(uchild_versicolorprob==0):\n",
    "                uchild_versicolorprob=1\n",
    "            if(lchild_setosaprob==0):\n",
    "                lchild_setosaprob=1\n",
    "            if(lchild_versicolorprob==0):\n",
    "                lchild_versicolorprob=1\n",
    "            #if(feature==2 and i==11):\n",
    "            #    print('uchild_countversicolor: ',uchild_countversicolor)\n",
    "            #    print('uchild_countsetosa: ',uchild_countsetosa)\n",
    "            #    print('lchild_countversicolor: ',lchild_countversicolor)\n",
    "            #    print('lchild_countsetosa: ',lchild_countsetosa)\n",
    "            entrpoy_uchild=-(uchild_setosaprob*math.log(uchild_setosaprob,2)+uchild_versicolorprob*math.log(uchild_versicolorprob,2))\n",
    "            entrpoy_lchild=-(lchild_setosaprob*math.log(lchild_setosaprob,2)+lchild_versicolorprob*math.log(lchild_versicolorprob,2))\n",
    "            #print('entrpoy_uchild :',entrpoy_uchild)\n",
    "            #print('entrpoy_lchild :',entrpoy_lchild)\n",
    "            totaldata=uchild.shape[0]+lchild.shape[0]\n",
    "            #if(feature==2 and splitpoint==3.0):\n",
    "              #  print('splitpoint:',splitpoint)\n",
    "               # print('uchild_countversicolor: ',uchild_countversicolor)\n",
    "                #print('uchild_countsetosa: ',uchild_countsetosa)\n",
    "               # print('lchild_countversicolor: ',lchild_countversicolor)\n",
    "               # print('lchild_countsetosa: ',lchild_countsetosa)\n",
    "               # print('uchild shape :',uchild.shape)\n",
    "               # print('uchild :\\n',uchild)\n",
    "               # print('lchild shape :',lchild.shape)\n",
    "               # print('lchild :\\n',lchild)\n",
    "               # print('entrpoy_uchild :',entrpoy_uchild)\n",
    "               # print('entrpoy_lchild :',entrpoy_lchild)\n",
    "               # print('-------------------')\n",
    "            weighted_avg=(entrpoy_uchild*(uchild.shape[0]/totaldata)+entrpoy_lchild*(lchild.shape[0]/totaldata))\n",
    "            info_gain=entropy_ofparent-weighted_avg\n",
    "            #if(info_gain==0):\n",
    "             #   print('******start******')\n",
    "              #  print('\\nwhere is zero index:',i)\n",
    "              #  print('where is zero feature:',feature)\n",
    "              #  print('where is zero splitpoint:',splitpoint)\n",
    "               # print('where is zero uchild shape:',uchild.shape)\n",
    "               # print('where is zero lchild shape:',lchild.shape,'\\n')\n",
    "                \n",
    "              #  print('where is zero uchild_countsetosa:',uchild_countsetosa)\n",
    "              #  print('where is zero uchild_countversicolor:',uchild_countversicolor)\n",
    "              #  print('where is zero lchild_countsetosa:',lchild_countsetosa)\n",
    "              #  print('where is zero lchild_countversicolor:',lchild_countversicolor,'\\n')\n",
    "                \n",
    "              #  print('where is zero uchild_setosaprob:',uchild_setosaprob)\n",
    "              #  print('where is zero uchild_versicolorprob:',uchild_versicolorprob)\n",
    "              #  print('where is zero lchild_setosaprob:',lchild_setosaprob)\n",
    "              #   print('where is zero lchild_versicolorprob:',lchild_versicolorprob,'\\n')\n",
    "                \n",
    "              #  print('where is zero setosa_inparent_prob:',setosa_inparent_prob)\n",
    "              #  print('where is zero versicolor_inparent_prob:',versicolor_inparent_prob)\n",
    "              #  print('where is zero entropy_ofparent',entropy_ofparent,'\\n')\n",
    "                \n",
    "              #  print('where is zero entrpoy_uchild:',entrpoy_uchild)\n",
    "              #  print('where is zero entrpoy_lchild:',entrpoy_lchild)\n",
    "              #  print('where is zero weighted_avg:',weighted_avg,'\\n')\n",
    "              #  print('------end--------')\n",
    "            if(info_gain>max_infogain):\n",
    "                max_infogain=info_gain\n",
    "                index_maxinfogain=i\n",
    "                value_maxinfogain=splitpoint\n",
    "                maxweighted_avg=weighted_avg\n",
    "                #uc1=entrpoy_uchild\n",
    "                #lc1=entrpoy_lchild\n",
    "                #mtotaldata=totaldata\n",
    "                muchild=uchild\n",
    "                mlchild=lchild\n",
    "                f_index=feature\n",
    "            #print('For Index: ',i,'Data: ',Data[i,0])\n",
    "            #if(feature==3):\n",
    "               # print('For Index: ',i,'Data: ',Data[i,feature])\n",
    "               # print('INFO GAIN: ',info_gain,'\\n')\n",
    "            uchild=np.zeros((1,5))\n",
    "            lchild=np.zeros((1,5))\n",
    "            uchild_countsetosa=uchild_countversicolor=lchild_countsetosa=lchild_countversicolor=0\n",
    "    return value_maxinfogain,max_infogain,mlchild,muchild,f_index,maxweighted_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,purity,klasslabel='',score=0,split=[],fidx=-1):\n",
    "        self.lchild=None       \n",
    "        self.rchild=None\n",
    "        self.klasslabel=klasslabel        \n",
    "        self.split=split\n",
    "        self.score=score\n",
    "        self.fidx=fidx\n",
    "        self.purity=purity\n",
    "        \n",
    "    def set_childs(self,lchild,rchild):\n",
    "        # YOUR CODE HERE\n",
    "        self.lchild=lchild\n",
    "        self.rchild=rchild\n",
    "        \n",
    "    def isleaf(self):\n",
    "        # YOUR CODE HERE\n",
    "        if self.lchild==None and self.rchild==None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "    def isless_than_eq(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    def get_str(self):        \n",
    "        if self.isleaf():\n",
    "            return 'C(class={},Purity={})'.format(self.klasslabel,self.purity)\n",
    "        else:\n",
    "            return 'I(Fidx={},Score={},Split={})'.format(self.fidx,self.score,self.split)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    ''' Implements the Decision Tree For Classification... '''\n",
    "    def __init__(self, purityp, exthreshold,maxdepth=10):        \n",
    "        self.purity=purityp\n",
    "        self.exthreshold=exthreshold\n",
    "        self.maxdepth=maxdepth\n",
    "        pass\n",
    "    def train(self, X, Y):\n",
    "        ''' Train Decision Tree using the given \n",
    "            X [m x d] data matrix and Y labels matrix\n",
    "            \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns:\n",
    "            -----------\n",
    "            Nothing\n",
    "           \n",
    "        '''\n",
    "        c1_prob=(X[:,4]==0).sum()/X.shape[0]\n",
    "        c2_prob=(X[:,4]==1).sum()/X.shape[0]\n",
    "        if(c1_prob==0):\n",
    "            c1_prob=1\n",
    "        if(c2_prob==0):\n",
    "            c2_prob=1\n",
    "        entropy_ofparent=-(c1_prob*math.log(c1_prob,2)+c2_prob*math.log(c2_prob,2))\n",
    "        nexamples,nfeatures=X.shape\n",
    "        ## now go and train a model for each class...\n",
    "        # YOUR CODE HERE\n",
    "        depth=0   \n",
    "        self.tree = self.build_tree(X,Y,0)\n",
    "        \n",
    "        \n",
    "    def build_tree(self, X, Y, depth):\n",
    "        # YOUR CODE HERE\n",
    "        #compare purity\n",
    "        #infogain call gain\n",
    "        #node.lchild(lchild)\n",
    "        #node.uchild(uchild)\n",
    "        c1_prob=(X[:,4]==0).sum()/X.shape[0]\n",
    "        c2_prob=(X[:,4]==1).sum()/X.shape[0]\n",
    "        checkpurity=0\n",
    "        if(c1_prob>c2_prob):\n",
    "            checkpurity=c1_prob\n",
    "            label=0\n",
    "        else:\n",
    "            checkpurity=c2_prob\n",
    "            label=1\n",
    "        node=Node(checkpurity)\n",
    "        print('888888888888888888888: ',checkpurity)\n",
    "        print('999999999999999999999: ',self.purity)\n",
    "        if(checkpurity>=self.purity): \n",
    "            node.klasslabel=label\n",
    "            return node\n",
    "        data,nfeatures=X.shape\n",
    "        if(data<=self.exthreshold or depth==self.maxdepth+1):\n",
    "            node.klasslabel=label\n",
    "            return node\n",
    "        splitpoint,infogain,Lchild,Uchild,f_index,maxweighted_avg=InfoGain(X)\n",
    "        node.split=splitpoint\n",
    "        #self.klasslabel=label        \n",
    "        self.score=maxweighted_avg\n",
    "        self.fidx=f_index\n",
    "        \n",
    "      #  print('Wanna see int:\\n',Lchild)\n",
    "       # print(type(Lchild))\n",
    "       # print(Lchild.shape)\n",
    "        left_targets=Lchild[:,4].copy()\n",
    "        #left_targets=np.zeros((Lchild[:,4].shape))\n",
    "        #left_targets=Lchild[:,4]\n",
    "        left_targets=left_targets.reshape((-1, 1))\n",
    "      #  print(left_targets.shape)\n",
    "      #  print(left_targets)\n",
    "        \n",
    "        right_targets=Uchild[:,4].copy()\n",
    "        #right_targets=np.zeros((Uchild[:,4].shape))\n",
    "        #right_targets=Uchild[:,4]\n",
    "        right_targets=right_targets.reshape((-1, 1))\n",
    "     #   print(right_targets.shape)\n",
    "      #  print(right_targets)\n",
    "        node.rchild=self.build_tree(Uchild,right_targets,depth+1)\n",
    "        node.lchild=self.build_tree(Lchild,left_targets,depth+1)\n",
    "        \n",
    "        return node\n",
    "        print (node.split,node.fidx,node.lchild,node.rchild)\n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        ''' Test the trained classifiers on the given set of examples \n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional test examples.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for each example, i.e. to which it belongs\n",
    "        '''\n",
    "        X=np.delete(X,(0),axis=1)\n",
    "        pclasses=[]\n",
    "        nexamples, nfeatures=X.shape\n",
    "        \n",
    "        for i in range(0,nexamples):\n",
    "            pclasses.append(self.predict(X[i]))\n",
    "        return pclasses\n",
    "    \n",
    "        \n",
    "        #pass\n",
    "           \n",
    "    def predict(self, X):\n",
    "        node=self.tree\n",
    "        while (not node.isleaf()):\n",
    "            if(X[node.fidx] == node.fidx):\n",
    "                node=node.lchild\n",
    "            else:\n",
    "                node=node.rchild\n",
    "        return node.klasslabel\n",
    "        #pass\n",
    "    \n",
    "    def _predict(self,node, X):\n",
    "   \n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __str__(self):\n",
    "        \n",
    "        return self.__print(self.tree)        \n",
    "        \n",
    "     \n",
    "    def find_depth(self):\n",
    "        return self._find_depth(self.tree)\n",
    "    \n",
    "    \n",
    "    def _find_depth(self,node):\n",
    "        if not node:\n",
    "            return\n",
    "        if node.isleaf():\n",
    "            return 1\n",
    "        else:\n",
    "            return max(self._find_depth(node.lchild),self._find_depth(node.rchild))+1\n",
    "    def __print(self,node,depth=0):\n",
    "        \n",
    "        ret = \"\"\n",
    "\n",
    "        # Print right branch\n",
    "        if node.rchild:\n",
    "            ret += self.__print(node.rchild,depth+1)\n",
    "\n",
    "        # Print own value\n",
    "        \n",
    "        ret += \"\\n\" + (\"    \"*depth) + node.get_str()\n",
    "\n",
    "        # Print left branch\n",
    "        if node.lchild:\n",
    "            ret += self.__print(node.lchild,depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtrain=X[0:120]\n",
    "Ytrain=Y[0:120]\n",
    "splitpoint,infogain,lchild,uchild,f_index,maxweighted_avg=InfoGain(X)\n",
    "#print('Splitpoint: ',splitpoint)\n",
    "#print('Max INFO GAIN: ',infogain)\n",
    "#print('Feature index: ',f_index)\n",
    "#print('Weighted averge: ',maxweighted_avg)\n",
    "#print('lchild :',lchild.shape)\n",
    "#print('lchild :\\n',lchild)\n",
    "#print('uchild :',uchild.shape)\n",
    "#print('uchild :\\n',uchild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (120, 5) Training True Class labels dimensions (120, 1)\n",
      " Test Data Set Dimensions= (29, 5) Test True Class labels dimensions (29, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and test-set...\n",
    "Y=Y.reshape((-1, 1))\n",
    "Xtrain=X[0:120]\n",
    "Ytrain=Y[0:120]\n",
    "Xtest=X[120:149]\n",
    "Ytest=Y[120:149]\n",
    "print (\" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape)   \n",
    "print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytest.shape)\n",
    "#we=np.array(X[:,4])\n",
    "#we=we.reshape((-1, 1))\n",
    "#print(we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets train a Decision Tree Classifier on Petal Length and Width\n",
    "#feat=[0,1]\n",
    "#dt=DecisionTree(0.95,5)\n",
    "#dt.train(Xtrain[:,feat],Ytrain)\n",
    "#print (dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets test it on the set of unseen examples...\n",
    "#feat=[0,1]\n",
    "#pclasses=dt.test(Xtest[:,feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888888888888888888888:  0.6583333333333333\n",
      "999999999999999999999:  0.95\n",
      "888888888888888888888:  1.0\n",
      "999999999999999999999:  0.95\n",
      "888888888888888888888:  1.0\n",
      "999999999999999999999:  0.95\n",
      "check [0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0]\n",
      "21\n",
      "Accuracy =  0.7241379310344828\n"
     ]
    }
   ],
   "source": [
    "#Lets Train on all four features....\n",
    "\n",
    "# Lets train a Decision Tree Classifier on Petal Length and Width\n",
    "\n",
    "feat=[0, 1, 2, 3]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain,Ytrain)\n",
    "#print(dt)\n",
    "#print(Xtest[:,4])\n",
    "#print(Xtest)\n",
    "Ytest=Xtest[:,4].copy()\n",
    "print('check',Ytest)\n",
    "pclasses=dt.test(Xtest)\n",
    "#print(pclasses)\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print (np.sum(pclasses==Ytest))\n",
    "print (\"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
